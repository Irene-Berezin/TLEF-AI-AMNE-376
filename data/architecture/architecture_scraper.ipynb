{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "268a2faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching members of Category:Ancient_Greek_architecture ...\n",
      "  → Found 59 total entries.\n",
      "  → 20 are actual files (ns=6).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kaiyan Zhang\\AppData\\Local\\Temp\\ipykernel_49012\\1032991668.py:181: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  delta = datetime.utcnow() - dt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing metadata to CSV and JSON...\n",
      "Downloading images and organizing into category folders…\n",
      "  [!] Could not copy 1047_-_Keramikos_Museum,_Athens_-_Vase_shaped_as_a_grain_silos,_700-650_BC_-_Photo_by_Giovanni_Dall'Orto_Nov_12_2009.jpg → downloaded_images\\Ancient_Greek_terracotta_figurines_in_the_Kerameikos_Archaeological_Museum_(Athens): [Errno 2] No such file or directory: \"downloaded_images\\\\Ancient_Greek_terracotta_figurines_in_the_Kerameikos_Archaeological_Museum_(Athens)\\\\1047_-_Keramikos_Museum,_Athens_-_Vase_shaped_as_a_grain_silos,_700-650_BC_-_Photo_by_Giovanni_Dall'Orto_Nov_12_2009.jpg\"\n",
      "  [!] Could not copy 1047_-_Keramikos_Museum,_Athens_-_Vase_shaped_as_a_grain_silos,_700-650_BC_-_Photo_by_Giovanni_Dall'Orto_Nov_12_2009.jpg → downloaded_images\\Attic_Geometric_pottery_in_the_Kerameikos_Archaeological_Museum_(Athens): [Errno 2] No such file or directory: \"downloaded_images\\\\Attic_Geometric_pottery_in_the_Kerameikos_Archaeological_Museum_(Athens)\\\\1047_-_Keramikos_Museum,_Athens_-_Vase_shaped_as_a_grain_silos,_700-650_BC_-_Photo_by_Giovanni_Dall'Orto_Nov_12_2009.jpg\"\n",
      "  [!] Could not copy 1048_-_Keramikos_Museum,_Athens_-_Vase_shaped_as_a_grain_silos,_700-650_BC_-_Photo_by_Giovanni_Dall'Orto_Nov_12_2009.jpg → downloaded_images\\Ancient_Greek_terracotta_figurines_in_the_Kerameikos_Archaeological_Museum_(Athens): [Errno 2] No such file or directory: \"downloaded_images\\\\Ancient_Greek_terracotta_figurines_in_the_Kerameikos_Archaeological_Museum_(Athens)\\\\1048_-_Keramikos_Museum,_Athens_-_Vase_shaped_as_a_grain_silos,_700-650_BC_-_Photo_by_Giovanni_Dall'Orto_Nov_12_2009.jpg\"\n",
      "  [!] Could not copy 1048_-_Keramikos_Museum,_Athens_-_Vase_shaped_as_a_grain_silos,_700-650_BC_-_Photo_by_Giovanni_Dall'Orto_Nov_12_2009.jpg → downloaded_images\\Attic_Geometric_pottery_in_the_Kerameikos_Archaeological_Museum_(Athens): [Errno 2] No such file or directory: \"downloaded_images\\\\Attic_Geometric_pottery_in_the_Kerameikos_Archaeological_Museum_(Athens)\\\\1048_-_Keramikos_Museum,_Athens_-_Vase_shaped_as_a_grain_silos,_700-650_BC_-_Photo_by_Giovanni_Dall'Orto_Nov_12_2009.jpg\"\n",
      "  [!] Could not create folder downloaded_images\\Uploaded_via_Campaign:wlm-gr: [WinError 267] 目录名称无效。: 'downloaded_images\\\\Uploaded_via_Campaign:wlm-gr'\n",
      "All done.\n",
      "  • Metadata CSV: ancient_greek_architecture_metadata.csv\n",
      "  • Metadata JSON: ancient_greek_architecture_metadata.json\n",
      "  • Downloaded images folder: downloaded_images/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse, unquote\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# CONFIGURATION\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "CATEGORY_TITLE       = \"Category:Ancient_Greek_architecture\"\n",
    "API_ENDPOINT         = \"https://commons.wikimedia.org/w/api.php\"\n",
    "OUTPUT_CSV           = \"ancient_greek_architecture_metadata.csv\"\n",
    "OUTPUT_JSON          = \"ancient_greek_architecture_metadata.json\"\n",
    "DOWNLOAD_BASE_FOLDER = \"downloaded_images\"\n",
    "\n",
    "# Your custom User-Agent per Wikimedia policy:\n",
    "USER_AGENT = \"AncientGreekArchDownloader/1.0 (kzhang83@student.ubc.ca)\"\n",
    "\n",
    "IIPROP = [\n",
    "    \"timestamp\",   # upload date/time\n",
    "    \"user\",        # who uploaded\n",
    "    \"url\",         # direct file URL\n",
    "    \"size\",        # file size in bytes\n",
    "    \"mime\",        # MIME type\n",
    "    \"metadata\",    # EXIF / embedded metadata if any\n",
    "]\n",
    "\n",
    "FETCH_CATEGORIES = True\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# UTILITY FUNCTIONS\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "def fetch_category_members(category, session, cmcontinue=None):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"list\": \"categorymembers\",\n",
    "        \"cmtitle\": category,\n",
    "        \"cmlimit\": \"500\",\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "    if cmcontinue:\n",
    "        params[\"cmcontinue\"] = cmcontinue\n",
    "\n",
    "    resp = session.get(API_ENDPOINT, params=params)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "def fetch_imageinfo(titles, session):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"imageinfo\",\n",
    "        \"titles\": \"|\".join(titles),\n",
    "        \"iiprop\": \"|\".join(IIPROP),\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "    resp = session.get(API_ENDPOINT, params=params)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "def fetch_categories_for_pages(pageids, session):\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"prop\": \"categories\",\n",
    "        \"pageids\": \"|\".join(str(pid) for pid in pageids),\n",
    "        \"cllimit\": \"max\",\n",
    "        \"format\": \"json\",\n",
    "    }\n",
    "    resp = session.get(API_ENDPOINT, params=params)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()\n",
    "\n",
    "def sanitize_category_name(cat_title):\n",
    "    if cat_title.startswith(\"Category:\"):\n",
    "        cat_title = cat_title[len(\"Category:\") :]\n",
    "    return cat_title.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "\n",
    "def sanitize_filename_from_url(url):\n",
    "    path = urlparse(url).path\n",
    "    name = os.path.basename(path)\n",
    "    return unquote(name)\n",
    "\n",
    "def download_image(url, save_path, session):\n",
    "    if os.path.exists(save_path):\n",
    "        return\n",
    "    headers = {\"User-Agent\": USER_AGENT}\n",
    "    resp = session.get(url, headers=headers, stream=True)\n",
    "    resp.raise_for_status()\n",
    "    with open(save_path, \"wb\") as fd:\n",
    "        for chunk in resp.iter_content(1024 * 8):\n",
    "            fd.write(chunk)\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "# MAIN\n",
    "# ─────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    # (1) Create a Session with custom User-Agent\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": USER_AGENT})\n",
    "\n",
    "    # (2) Fetch all category members\n",
    "    print(f\"Fetching members of {CATEGORY_TITLE} ...\")\n",
    "    cmcontinue = None\n",
    "    all_members = []\n",
    "    while True:\n",
    "        data = fetch_category_members(CATEGORY_TITLE, session, cmcontinue=cmcontinue)\n",
    "        all_members.extend(data[\"query\"][\"categorymembers\"])\n",
    "        if \"continue\" in data:\n",
    "            cmcontinue = data[\"continue\"][\"cmcontinue\"]\n",
    "            time.sleep(0.1)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    print(f\"  → Found {len(all_members)} total entries.\")\n",
    "    file_members = [m for m in all_members if m[\"ns\"] == 6]\n",
    "    print(f\"  → {len(file_members)} are actual files (ns=6).\")\n",
    "\n",
    "    # (3) Batch‐query imageinfo & categories\n",
    "    metadata_records = []\n",
    "    chunk_size = 50\n",
    "    for i in range(0, len(file_members), chunk_size):\n",
    "        chunk = file_members[i : i + chunk_size]\n",
    "        titles = [m[\"title\"] for m in chunk]\n",
    "        pageid_list = [m[\"pageid\"] for m in chunk]\n",
    "\n",
    "        img_data = fetch_imageinfo(titles, session)\n",
    "        pages = img_data[\"query\"][\"pages\"]\n",
    "\n",
    "        if FETCH_CATEGORIES:\n",
    "            cat_data = fetch_categories_for_pages(pageid_list, session)\n",
    "            cat_pages = cat_data[\"query\"][\"pages\"]\n",
    "        else:\n",
    "            cat_pages = {}\n",
    "\n",
    "        for pid, pdata in pages.items():\n",
    "            record = {\n",
    "                \"pageid\": int(pid),\n",
    "                \"title\": pdata.get(\"title\", \"\"),\n",
    "                \"timestamp\": None,\n",
    "                \"uploader\": None,\n",
    "                \"file_url\": None,\n",
    "                \"filesize\": None,\n",
    "                \"mime\": None,\n",
    "                \"exif\": {},\n",
    "                \"categories\": [],\n",
    "            }\n",
    "\n",
    "            if \"imageinfo\" in pdata:\n",
    "                ii = pdata[\"imageinfo\"][0]\n",
    "                record[\"timestamp\"] = ii.get(\"timestamp\")\n",
    "                record[\"uploader\"]  = ii.get(\"user\")\n",
    "                record[\"file_url\"]  = ii.get(\"url\")\n",
    "                record[\"filesize\"]  = ii.get(\"size\")\n",
    "                record[\"mime\"]      = ii.get(\"mime\")\n",
    "\n",
    "                md_list = ii.get(\"metadata\", [])\n",
    "                exif_dict = {}\n",
    "                for md in md_list:\n",
    "                    name = md.get(\"name\")\n",
    "                    val  = md.get(\"value\")\n",
    "                    if name and val:\n",
    "                        exif_dict[name] = val\n",
    "                record[\"exif\"] = exif_dict\n",
    "\n",
    "            if FETCH_CATEGORIES and pid in cat_pages:\n",
    "                cats = cat_pages[pid].get(\"categories\", [])\n",
    "                record[\"categories\"] = [c[\"title\"] for c in cats]\n",
    "\n",
    "            metadata_records.append(record)\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # (4) Compute “days_since_upload”\n",
    "    for rec in metadata_records:\n",
    "        ts = rec[\"timestamp\"]\n",
    "        if ts:\n",
    "            dt = datetime.strptime(ts, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            delta = datetime.utcnow() - dt\n",
    "            rec[\"days_since_upload\"] = delta.days\n",
    "        else:\n",
    "            rec[\"days_since_upload\"] = None\n",
    "\n",
    "    # (5) Write metadata CSV & JSON\n",
    "    print(\"Writing metadata to CSV and JSON...\")\n",
    "    with open(OUTPUT_CSV, mode=\"w\", newline=\"\", encoding=\"utf-8\") as fh:\n",
    "        fieldnames = [\n",
    "            \"pageid\",\n",
    "            \"title\",\n",
    "            \"timestamp\",\n",
    "            \"days_since_upload\",\n",
    "            \"uploader\",\n",
    "            \"file_url\",\n",
    "            \"filesize\",\n",
    "            \"mime\",\n",
    "            \"categories\",\n",
    "            \"exif\",\n",
    "        ]\n",
    "        writer = csv.DictWriter(fh, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for rec in metadata_records:\n",
    "            rec_row = {\n",
    "                \"pageid\": rec[\"pageid\"],\n",
    "                \"title\": rec[\"title\"],\n",
    "                \"timestamp\": rec[\"timestamp\"],\n",
    "                \"days_since_upload\": rec[\"days_since_upload\"],\n",
    "                \"uploader\": rec[\"uploader\"],\n",
    "                \"file_url\": rec[\"file_url\"],\n",
    "                \"filesize\": rec[\"filesize\"],\n",
    "                \"mime\": rec[\"mime\"],\n",
    "                \"categories\": json.dumps(rec[\"categories\"], ensure_ascii=False),\n",
    "                \"exif\": json.dumps(rec[\"exif\"], ensure_ascii=False),\n",
    "            }\n",
    "            writer.writerow(rec_row)\n",
    "\n",
    "    with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as fh:\n",
    "        json.dump(metadata_records, fh, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # (6) Prepare base download folder\n",
    "    if not os.path.exists(DOWNLOAD_BASE_FOLDER):\n",
    "        os.makedirs(DOWNLOAD_BASE_FOLDER)\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    # (7) Download each image and copy into category folders\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    print(\"Downloading images and organizing into category folders…\")\n",
    "    for rec in metadata_records:\n",
    "        url = rec[\"file_url\"]\n",
    "        if not url:\n",
    "            continue\n",
    "\n",
    "        local_filename = sanitize_filename_from_url(url)\n",
    "        temp_path = os.path.join(DOWNLOAD_BASE_FOLDER, local_filename)\n",
    "\n",
    "        # (1) Download the image once (with proper User-Agent).\n",
    "        try:\n",
    "            download_image(url, temp_path, session)\n",
    "        except Exception as e:\n",
    "            print(f\"  [!] Failed to download {url}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # (2) If download didn’t produce a file, skip copying entirely.\n",
    "        if not os.path.exists(temp_path):\n",
    "            # Download must have quietly failed; don’t attempt any folder/copy.\n",
    "            continue\n",
    "\n",
    "        # (3) Now iterate over each category; ensure the folder exists before copying.\n",
    "        for cat_full in rec[\"categories\"]:\n",
    "            folder_name = sanitize_category_name(cat_full)\n",
    "            target_dir = os.path.join(DOWNLOAD_BASE_FOLDER, folder_name)\n",
    "\n",
    "            # ─── Create the category directory before opening the file ───\n",
    "            try:\n",
    "                os.makedirs(target_dir, exist_ok=True)\n",
    "            except Exception as e:\n",
    "                print(f\"  [!] Could not create folder {target_dir}: {e}\")\n",
    "                # If for some reason mkdir fails, skip copying into this category.\n",
    "                continue\n",
    "\n",
    "            target_path = os.path.join(target_dir, local_filename)\n",
    "\n",
    "            # (4) Finally, copy the downloaded file into that folder.\n",
    "            #     We wrap this in try/except so that even if something odd happens,\n",
    "            #     the script will not crash out with FileNotFoundError.\n",
    "            if not os.path.exists(target_path):\n",
    "                try:\n",
    "                    with open(temp_path, \"rb\") as src_fd, open(target_path, \"wb\") as dst_fd:\n",
    "                        dst_fd.write(src_fd.read())\n",
    "                except Exception as e:\n",
    "                    print(f\"  [!] Could not copy {local_filename} → {target_dir}: {e}\")\n",
    "                    # Continue on to the next category or image\n",
    "                    continue\n",
    "\n",
    "print(\"All done.\")\n",
    "print(f\"  • Metadata CSV: {OUTPUT_CSV}\")\n",
    "print(f\"  • Metadata JSON: {OUTPUT_JSON}\")\n",
    "print(f\"  • Downloaded images folder: {DOWNLOAD_BASE_FOLDER}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173c166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
